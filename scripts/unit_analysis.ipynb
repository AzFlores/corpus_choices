{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "11a25f832be08a092d19430d56f087bf0692000e4a4edb12a321ecbcc5e6518e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Unit Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#import required modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk \n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\AzF\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3155: DtypeWarning: Columns (2,3,4,11,13,15,20) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#load in dataset\n",
    "childes = pd.read_csv(\"C:/Users/AzF/unit analysis/childes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only desired columns\n",
    "childes_1 = childes[['stem', 'type', 'corpus_name', 'speaker_code', 'speaker_name', 'speaker_role','target_child_age']]\n",
    "#childes_1 = childes[['stem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# childes.index\n",
    "# childes.columns\n",
    "#childes_1.dtypes\n",
    "#childes.ndim\n",
    "# childes.shape\n",
    "# childes.size\n",
    "#childes.memory_usage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-12-a666fabdcafd>:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  childes_1['stem'] = childes_1['stem'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "#lowercase stem\n",
    "childes_1['stem'] = childes_1['stem'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to map punctuation values \n",
    "def set_value(row_number, assigned_value): \n",
    "    return assigned_value[row_number] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary \n",
    "type_symbol ={'question' : '?', 'declarative' : \".\",'trail off':\"...\",\"interruption\":\"-\",'trail off question': \"...?\",\n",
    "'imperative_emphatic': \"+\",'quotation next line':\"''+\",'quotation precedes':\"^''\",\n",
    "'interruption question': \"-?\", 'self interruption':'@?','self interruption question':'@-?',\n",
    "'broken for coding':'#','missing CA terminator':\"-CA\",'question exclamation':\"?!\"} \n",
    "\n",
    "# Add a new column named 'symbol' \n",
    "childes_1['symbol'] = childes_1['type'].apply(set_value, args =(type_symbol, ))\n",
    "  \n",
    "#childes_1 = childes_1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate stem with punctuation (e.g \"He was acquitted?\")\n",
    "childes_1[\"stem_punc\"] = childes_1[\"stem\"] + childes_1[\"symbol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep rows without NA\n",
    "childes_2 = childes_1[childes_1['stem'].notna()]"
   ]
  },
  {
   "source": [
    "## Create Frequency Counts\n",
    "###  1.-No parsing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split words in each stem row,count frequencies \n",
    "#freq_series=pd.Series(np.concatenate([x.split() for x in childes_2.stem])).value_counts()[:32000]\n",
    "\n",
    "#count \n",
    "punc_series=pd.Series(np.concatenate([x.split(\"-\") for x in childes_2.type])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conver pd.series into df\n",
    "freq_df = freq_series.to_frame()\n",
    "\n",
    "#reset index\n",
    "freq_df=freq_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "freq_df= freq_df.rename(columns={\"index\": \"word\", \"0\": \"freq\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add additional columns\n",
    "freq_df['problem'] = np.nan\n",
    "freq_df['can_be_noun'] = np.nan\n",
    "freq_df['can_be_verb'] = np.nan\n",
    "freq_df['replacement'] = np.nan\n",
    "freq_df['parse'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe\n",
    "freq_df.to_csv(r\"C:\\Users\\AzF\\unit analysis\\manual_parsing.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only rows with the following (_,-,')\n",
    "compound_markers = ['_','-',',']\n",
    "compound_df= freq_df[freq_df[\"word\"].str.contains(\"_\")]\n",
    "apostrophe_df= freq_df[freq_df[\"word\"].str.contains(\"'\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_df.to_csv(r\"C:\\Users\\AzF\\unit analysis\\compound_df.csv\",index=False)\n",
    "dash_df.to_csv(r\"C:\\Users\\AzF\\unit analysis\\dash_df.csv\",index=False)\n",
    "apostrophe_df.to_csv(r\"C:\\Users\\AzF\\unit analysis\\apostrophe_df.csv\",index=False)\n",
    "punc_series.to_csv(r\"C:\\Users\\AzF\\unit analysis\\punc_freq.csv\",index=False)\n"
   ]
  },
  {
   "source": [],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}